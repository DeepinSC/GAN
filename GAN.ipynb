{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 1000\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n) # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 0.631179928779602/0.7063143253326416 G: 0.6789350509643555 (Real: [4.0076363402605057, 1.1413296380464122], Fake: [0.068702988624572747, 0.0039269247057367338]) \n",
      "\n",
      "1000: D: 0.004279997665435076/0.033405136317014694 G: 2.481670379638672 (Real: [3.9770264136791229, 1.1689959327686088], Fake: [1.5254266849160194, 0.59404333609512761]) \n",
      "\n",
      "2000: D: 1.178526759147644/0.4246387779712677 G: 0.5061546564102173 (Real: [4.0600325167179108, 1.1762936879825203], Fake: [5.1311499750614162, 1.5991883419999227]) \n",
      "\n",
      "3000: D: 0.6325548887252808/0.692500114440918 G: 0.5996463894844055 (Real: [3.6988616168498991, 1.3460651968668513], Fake: [3.2544255179166792, 1.0786315723258608]) \n",
      "\n",
      "4000: D: 0.7742937803268433/0.7821707725524902 G: 0.5732417106628418 (Real: [4.0002675156295302, 1.3968568361582689], Fake: [3.7895926547050478, 1.1923193394992302]) \n",
      "\n",
      "5000: D: 0.6485586166381836/0.5471310615539551 G: 0.5902073979377747 (Real: [3.8330138885974883, 1.1396777801909133], Fake: [3.3151447919011114, 1.5215830699143358]) \n",
      "\n",
      "6000: D: 0.8161524534225464/0.4328884184360504 G: 0.9055407643318176 (Real: [3.9227592635154722, 1.3052174421589444], Fake: [4.074953773021698, 1.12403488287076]) \n",
      "\n",
      "7000: D: 0.5042588710784912/0.5568366646766663 G: 0.6764988899230957 (Real: [4.0326465862989425, 1.4032774080861783], Fake: [3.9351244807243346, 1.2860322088476599]) \n",
      "\n",
      "8000: D: 0.7114105224609375/0.7675936818122864 G: 0.7784528732299805 (Real: [3.8710311750508843, 1.2877216626733481], Fake: [4.0036671221256253, 1.2463589187906197]) \n",
      "\n",
      "9000: D: 0.5727161169052124/0.6483486294746399 G: 0.6379384994506836 (Real: [3.9727543104439973, 1.3182645941230293], Fake: [3.7762344121932983, 1.3738520844328679]) \n",
      "\n",
      "10000: D: 0.8970023989677429/0.7106610536575317 G: 0.7664755582809448 (Real: [4.1335194700956341, 1.263080742252777], Fake: [4.5266387474536893, 1.1299905205205312]) \n",
      "\n",
      "11000: D: 0.46626392006874084/0.784315824508667 G: 0.9813958406448364 (Real: [3.9561713194847106, 1.2218795344497126], Fake: [4.3103503370285035, 1.1575165239069425]) \n",
      "\n",
      "12000: D: 0.6775522828102112/0.6933389902114868 G: 0.8801161646842957 (Real: [4.238347385525703, 1.3464183975907165], Fake: [4.2250892746448514, 1.1459987713346027]) \n",
      "\n",
      "13000: D: 0.6036780476570129/0.6437835693359375 G: 1.1017298698425293 (Real: [3.9215511560440062, 1.1795858484536117], Fake: [4.0717453956604004, 1.3812082185197363]) \n",
      "\n",
      "14000: D: 0.46128445863723755/0.9779653549194336 G: 0.7606603503227234 (Real: [4.0394135797023774, 1.1817704159694238], Fake: [3.911877012848854, 1.233723443099525]) \n",
      "\n",
      "15000: D: 0.5138565897941589/0.8160427212715149 G: 1.598457932472229 (Real: [3.9997588038444518, 1.168907608522417], Fake: [3.8670341569185256, 1.3115407852432786]) \n",
      "\n",
      "16000: D: 0.08118937909603119/0.528673529624939 G: 0.5761961936950684 (Real: [3.9402995359897615, 1.2199678183287086], Fake: [3.9756756973266603, 1.2035606738883449]) \n",
      "\n",
      "17000: D: 0.0710267722606659/0.8373845219612122 G: 0.9170487523078918 (Real: [4.0255021297931668, 1.2046111631268499], Fake: [4.1135096526145931, 1.2554039362992251]) \n",
      "\n",
      "18000: D: 0.10271970182657242/0.596851110458374 G: 0.7377385497093201 (Real: [4.0210388129949566, 1.4211023236714038], Fake: [3.7182044732570647, 1.1553632158780416]) \n",
      "\n",
      "19000: D: 0.07926743477582932/0.6116293668746948 G: 1.5366616249084473 (Real: [3.9584601479768753, 1.2119665789611234], Fake: [4.0277221488952639, 1.1882874208761849]) \n",
      "\n",
      "20000: D: 0.062078654766082764/0.35847198963165283 G: 1.4917813539505005 (Real: [4.0303812247514728, 1.1455881891653148], Fake: [4.1769953608512882, 1.1197935187185841]) \n",
      "\n",
      "21000: D: 0.035282790660858154/2.2081875801086426 G: 1.1827365159988403 (Real: [3.938761801123619, 1.3951982137452528], Fake: [3.9001869010925292, 1.2133316914965133]) \n",
      "\n",
      "22000: D: 0.12722288072109222/0.47190526127815247 G: 1.900809645652771 (Real: [4.001739994883537, 1.2397896142471754], Fake: [3.9850492823123931, 1.2189259401175907]) \n",
      "\n",
      "23000: D: 1.859295129776001/0.9880667328834534 G: 1.940767526626587 (Real: [3.9149953275918961, 1.1552699970913207], Fake: [4.237200208902359, 1.2113482228158996]) \n",
      "\n",
      "24000: D: 1.1557196378707886/1.08546781539917 G: 0.8415376543998718 (Real: [4.1053869616985317, 1.1691321933802781], Fake: [3.7154173642396926, 1.2787267686217332]) \n",
      "\n",
      "25000: D: 0.6123212575912476/0.788023054599762 G: 0.5699218511581421 (Real: [3.9908181196451187, 1.2396697782750641], Fake: [3.8659631985425951, 1.1027355823280849]) \n",
      "\n",
      "26000: D: 2.3830454349517822/0.8168770670890808 G: 1.1879279613494873 (Real: [4.0547846293449403, 1.181854542122821], Fake: [4.2751797223091126, 1.3069122800782353]) \n",
      "\n",
      "27000: D: 1.3432402610778809/0.24936385452747345 G: 0.841004490852356 (Real: [4.1080593019723892, 1.3805300083213043], Fake: [4.6527990245819089, 1.4979592167477476]) \n",
      "\n",
      "28000: D: 0.6415276527404785/0.5648185610771179 G: 0.8451899290084839 (Real: [3.8896582525968553, 1.2951311126278786], Fake: [4.3870329058170316, 1.2623176780514367]) \n",
      "\n",
      "29000: D: 0.8218584060668945/1.4461029767990112 G: 0.24312719702720642 (Real: [3.996302320957184, 1.1936895080166636], Fake: [3.1509235006570817, 1.1087596452909325]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \\n\" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "stats(extract(d_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
